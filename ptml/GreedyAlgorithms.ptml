<html>
    <head>
        <link href="style.css" rel="stylesheet" type="text/css"/>
        <title>
            Design and Analysis of Algorithms: Greedy Algorithms
        </title>
    </head>

    <body>
<!--include menu.txt -->
        <h1>
            Design and Analysis of Algorithms: Greedy Algorithms
        </h1>

            <div style="text-align:center">
                <p>
                    <img
                    src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/bc/The_worship_of_Mammon.jpg/170px-The_worship_of_Mammon.jpg">
                    <br>
                </p>
            </div>

            <details>
                <summary class="sum1">
                    A family of problems and approriate solutions
                </summary>

                <p>
                    It is important to recognize that we have been
                    dealing with a family of problems and solutions
                    to those problems:
                </p>
                <ul>
                    <li><b>Optimal substructure</b>:
                        <br>Recursive solution.
                    </li>
                    <li><b>Optimal substructure with overlapping sub-problems</b>:
                        <br>Recursion with memoization or dynamic programming.
                    </li>
                    <li>
                        <b>Optimal substructure where only the
                            locally optimal choice matters</b>:
                        <br>Greedy algorithms.
                    </li>
                </ul>
            </details>


            <details>
                <summary class="sum1">
                    What is a greedy algorithm?
                </summary>

                <p>
                We have an optimization problem.
                <br>
                At each step of the algorithm, we have to make a choice, e.g.,
                cut the rod here, or cut it there.
                <br>
                Sometimes, we need to calculate the result of all possible
                choices.
                </p>
                <ul>
                    <li>When we do so from the top down, we have a <i>recursive
                    algorithm</i>. A naive recursive algorithm may be very
                    expensive, but we can significantly reduce its run-time by
                    <i>memoizing</i> it.
                    </li>
                    <li>When we do this calculation from the bottom up, we are
                        employing <i>dynamic programming</i>.
                    </li>
                </ul>

                <p>
                But sometimes, we can do much better than either of those
                choices. Sometimes, we don't need to consider the global
                situation at all: we can simply make the best choice among the
                options provided by the local problem we face, and then
                continue that procedure for all subsequent local problems.
                <br>
                <br>
                An algorithm that operates in such a fashion is a <i>greedy
                algorithm</i>. (The name comes from the idea that the
                algorithm <i>greedily</i> grabs the best choice available to it right
                away.)
                <br>
                <br>
                Clearly, not all problems can be solved by greedy algorithms.
                Consider this simple shortest path problem:
                <br>
                <br>
                <img src="graphics/ShortPath.png"
                    height="240" width="360">
                <br>
                <br>
                A greedy algorithm choosing the shortest path from <i>a</i> to <i>d</i> will
                wrongly head to <i>b</i> first, rather than to <i>c</i>.
                </p>

                <figure>
                    <iframe width="560" height="315"
                        src="https://www.youtube.com/embed/rOOyJNgyW_o"
                        frameborder="0" allowfullscreen></iframe>
                    <figcaption>
                        Introduction to greedy algorithms
                    </figcaption>
                </figure>

            </details>

            <details>
                <summary class="sum1">
                    An activity selection problem
                </summary>

                <p>
                    Suppose we need to schedule a lecture hall with the goal of
                    maximizing the number of lectures it can hold, given the
                    constraint that no lectures can share the space.
                    <br>
                    We have the activities sorted in order of increasing finish
                    time:
                    <br>
                    <i>f<sub>1</sub> &le; f<sub>2</sub> &le; f<sub>3</sub>
                        &le; ... &le; f<sub>n - 1</sub> &le; f<sub>n</sub></i>.
                    <br>
                    <br>
                    We might have the following set of activities:
                </p>
                <table>
                    <tr>
                        <th>
                            <i>i</i>
                        </th>
                        <th>
                            1
                        </th>
                        <th>
                            2
                        </th>
                        <th>
                            3
                        </th>
                        <th>
                            4
                        </th>
                        <th>
                            5
                        </th>
                        <th>
                            6
                        </th>
                        <th>
                            7
                        </th>
                        <th>
                            8
                        </th>
                        <th>
                            9
                        </th>
                        <th>
                            10
                        </th>
                        <th>
                            11
                        </th>
                    </tr>
                    <tr>
                        <th>
                            <i>s<sub>i</sub></i>
                        </th>
                        <td>
                            1
                        </td>
                        <td>
                            3
                        </td>
                        <td>
                            0
                        </td>
                        <td>
                            5
                        </td>
                        <td>
                            3
                        </td>
                        <td>
                            5
                        </td>
                        <td>
                            6
                        </td>
                        <td>
                            8
                        </td>
                        <td>
                            8
                        </td>
                        <td>
                            2
                        </td>
                        <td>
                            12
                        </td>
                    </tr>
                    <tr>
                        <th>
                            <i>f<sub>i</sub></i>
                        </th>
                        <td>
                            4
                        </td>
                        <td>
                            5
                        </td>
                        <td>
                            6
                        </td>
                        <td>
                            7
                        </td>
                        <td>
                            9
                        </td>
                        <td>
                            9
                        </td>
                        <td>
                            10
                        </td>
                        <td>
                            11
                        </td>
                        <td>
                            12
                        </td>
                        <td>
                            14
                        </td>
                        <td>
                            16
                        </td>
                    </tr>
                </table>

                <p>
                    <br>
                    We have several sets of mutually compatible lectures, e.g.:
                    <br>
                    {<i>a</i><sub>3</sub>,
                    <i>a</i><sub>9</sub>,
                    <i>a</i><sub>11</sub>}
                    <br>
                    However, this set is larger:
                    <br>
                    {<i>a</i><sub>1</sub>,
                    <i>a</i><sub>4</sub>,
                    <i>a</i><sub>8</sub>,
                    <i>a</i><sub>11</sub>}
                    <br>
                    <br>
                    How do we find the maximum subset of lectures we can
                    schedule?
                </p>


                <details>
                    <summary class="sum2">
                    The optimal sub-structure of the problem
                    </summary>

                    <p>
                    It is easy to see that the problem exhibits optimal
                    substructure. <i>If</i> the optimal solution includes a
                    lecture from 4 to 6, then we have the sub-problems of
                    scheduling lectures that end by 4, and lectures that start
                    at 6 or after. Obviously, we must solve each of those
                    sub-problems in an optimal way, or our solution will not be
                    optimal! (Think of our problem of traveling from MetroTech
                    Center to Yankee Stadium via Grand Central.) Our textbook
                    calls this a "cut-and-paste" argument: we can cut an
                    optimal set of lectures ending by 4 and paste it into our
                    supposed optimal solution: if the solution was different
                    before 4, we have improved it, so it wasn't actually
                    optimal!
                    <br>
                    <br>
                    It is straight forward to see that we
                    can solve this problem with a recursive,
                    memoized algorithm -- we examine each
                    possible "cut" of a "middle" lecture, and recursively solve
                    the start-to-middle problem, and the middle-to-end problem.
                    Or we could use a bottom-up dynamic programming algorithm,
                    developed from the recursive solution in the same way we
                    saw in our last lecture.
                    </p>
                </details>

                <details>
                    <summary class="sum2">
                    Making the greedy choice
                    </summary>

                    <p>
                    But we can solve this problem much more efficiently. At
                    each step in solving it, we can make a completely <i>local</i>
                    choice: what activity (still possible) finishes earliest?
                    <br>
                    <br>
                    Since we have sorted the activities in order of increasing
                    finish time, we simply choose <i>a</i><sub>1</sub>, since
                    it is guaranteed to finish at least tied for first.
                    <br>
                    <br>
                    The proof that this will give us a maximal set of
                    activities is trivial: Let us suppose <i>a</i><sub>j</sub>
                    is the activity in some set that finishes first, but that
                    there is a maximal subset A<sub>k</sub>
                    that does <i>not</i> include
                    <i>a</i><sub>j</sub>. We simply remove the first element of
                    A<sub>k</sub> and substitute in <i>a</i><sub>j</sub>. This
                    is guaranteed to be a compatible set of activities, since
                    <i>a</i><sub>j</sub> finishes first, and it will be
                    maximal, since it is the same size as A<sub>k</sub>. (Note
                    that the textbook offers us an example of such sets on page
                    415.)
                    </p>

                </details>

                <details>
                    <summary class="sum2">
                    A recursive greedy algorithm
                    </summary>

                    <p>
                    The algorithm is straightforward:
                    find the first compatible activity, then call
                    the algorithm again with the rest of the activity list.
                    <br>
                    <br>
                    One trick worth noting:
                    the authors put a dummy activity in the
                    first position of the list, so that there
                    is no special first call of the function.
                    <br>
                    There is a <b>design pattern</b> here: oftentimes, it is
                    better to modify a data structure than to do
                    special coding for end cases.
                    </p>
                    <p>
                        <code>
                        <pre>
            Recursive-Activity-Selector(s, f, k, n)
                m = k + 1
                while m &le; n and s[m] &lt; f[k]
                    m = m + 1
                if m &le; n
                    // + here is set union!
                    return a[m] + Recursive-Activity-Selector(s, f, m, n)
                else
                    return NIL
                        </pre>
                        </code>
                    </p>
                </details>


                <details>
                    <summary class="sum2">
                    An iterative greedy algorithm
                    </summary>

                    <p>
                    As usual, it is fairly simple to transform the recursive
                    algorithm into an iterative version. The authors discuss tail
                    recursion in this section: let's review what this is.
                    </p>
                    <p>
                        <code>
                        <pre>
            Greedy-Activity-Selector(s, f)
                n = s.length
                A = {a[1]}
                k = 1
                for m = 2 to n
                    if s[m] &gt; f[k]
                        A = A + {a[m]} // + is set union!
                        k = m
                return A
                        </pre>
                        </code>
                    </p>
                </details>
                <details>
                  <summary class="sum2">
                  Run the python code for greedy activity selector
                  </summary>
                  <p>
                      In the console below, type or paste:
                      <br/>
                      <code>
                          !git clone https://gist.github.com/bb22ea72d8b15fa965d2f50e6798ae50.git
                          <br/>
                          cd bb22ea72d8b15fa965d2f50e6798ae50
                          <br/>
                          from greedy_algorithms import *
                          <br/>
                          print("start: ", start, "\nfinish: ", finish)
                          <br/>
                          greedy_activity_selector(start, finish)
                          <br/>
                      </code>
                  </p>
                  <!--include python_anywhere.txt -->
                </details>

            </details>

            <details>
                <summary class="sum1">
                    Elements of the greedy strategy
                </summary>

                <p>
                <img
                src="https://upload.wikimedia.org/wikipedia/commons/thumb/d/da/Greedy_algorithm_36_cents.svg/280px-Greedy_algorithm_36_cents.svg.png">
                </p>

                <ol>
                    <li>Determine the optimal substructure of the problem.
                    </li>
                    <li>Develop a recursive solution.
                    </li>
                    <li>Show if we make the greedy choice, that only one
                        sub-problem remains.
                    </li>
                    <li>Prove that it is always safe to make the greedy
                        choice.
                    </li>
                    <li>Develop a recursive algorithm that implements the
                        greedy strategy.
                    </li>
                    <li>Convert the recursive algorithm to an iterative algorithm
                    </li>
                </ol>

                <details>
                    <summary class="sum2">
                    Greedy-choice property
                    </summary>

                    <p>
                    <img
                    src="https://upload.wikimedia.org/wikipedia/commons/8/8c/Greedy-search-path-example.gif">
                    <br>
                    <br>
                    For a greedy algorithm to work, the optimal choice must not
                    depend upon any sub-problems or any future choices.
                    <br>
                    <br>
                    To prove that a greedy choice will be appropriate for some
                    problem, we typically examine an optimal solution, and then
                    show that substituting in a greedy choice will also yield an
                    optimal solution.
                    </p>
                </details>


                <details>
                    <summary class="sum2">
                    Optimal substructure
                    </summary>

                    <p>
                    This is simpler then for dynamic programming
                    problems:
                    all we need to do is show that a
                    greedy choice combined with
                    an optimal solution to the sub problem of the rest of
                    the data gives us an optimal solution to the
                    original problem.
                    We use induction to show that making the
                    greedy choice at every
                    step produces an optimal solution.
                    </p>
                </details>


                <details>
                    <summary class="sum2">
                    Greedy versus dynamic programming
                    </summary>

                    <p>
                    Two knapsack problems:
                    </p>

                    <ol>
                        <li>A thief can take entire items from a store or not, and
                            put them in his knapsack.
                        </li>
                        <li>A thief can take whatever fraction of an item he wants,
                            and put it in his knapsack.
                        </li>
                    </ol>

                    <p>
                    The latter can be solved with a greedy algorithm, the former
                    cannot.
                    </p>
                </details>
            </details>


            <details>
                <summary class="sum1">
                    Huffman codes
                </summary>

                <p>
                <img
                src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/82/Huffman_tree_2.svg/220px-Huffman_tree_2.svg.png">
                <br>
                <br>
                Hoffman coding is away of compressing data that consists of
                characters buy creating short binary representations for the
                characters that occur most frequently in the data, and using longer
                representations for characters that occur less frequently.
                </p>

                <figure>
                    <iframe width="560" height="315"
                        src="https://www.youtube.com/embed/dM6us854Jk0"
                        frameborder="0" allowfullscreen></iframe>
                    <figcaption>
                        Huffman coding
                    </figcaption>
                </figure>

                <details>
                    <summary class="sum2">
                    Prefix codes
                    </summary>

                    <p>
                    Prefix codes are coding schemes in which no codeword
                    is a prefix of a different codeword.
                    <br>
                    This makes decoding easier -- no lookahead.
                    (<b>else</b> and <b>else-if</b>)
                    <br />
                    It means that we never hit two letters on the same path
                    down the tree!
                    </p>

                    <table>
                        <tr>
                            <td>
                            </td>
                            <th>
                                a
                            </th>
                            <th>
                                b
                            </th>
                            <th>
                                c
                            </th>
                            <th>
                                d
                            </th>
                            <th>
                                e
                            </th>
                            <th>
                                f
                            </th>
                        </tr>
                        <tr>
                            <th>
                                Frequency (in 1000s)
                            </th>
                            <td>
                                45
                            </td>
                            <td>
                                13
                            </td>
                            <td>
                                12
                            </td>
                            <td>
                                16
                            </td>
                            <td>
                                9
                            </td>
                            <td>
                                5
                            </td>
                        </tr>
                        <tr>
                            <th>
                                Codeword
                            </th>
                            <td>
                                0
                            </td>
                            <td>
                                101
                            </td>
                            <td>
                                100
                            </td>
                            <td>
                                111
                            </td>
                            <td>
                                1101
                            </td>
                            <td>
                                1100
                            </td>
                        </tr>
                    </table>
                </details>

                <details>
                    <summary class="sum2">
                    Constructing a Huffman code
                    </summary>

                    <p>
                        We build a binary tree from the bottom-up, starting with the
                        two least-frequent characters, and building up from there. This
                        ensures the least-frequent characters have the longest codes.
                        <br>
                        <br>
                        Consider the phrase "Mississippi River".
                        This is 136 bits in 8-bit ASCII encoding.
                        <br>
                        <br>
                        Here is the Huffman coding for it:
                        <br>
                        <img src="graphics/Huffman.png">
                        <br>
                        <br>
                        I = 00
                        <br>
                        S = 01
                        <br>
                        P = 100
                        <br>
                        R - 101
                        <br>
                        M = 1100
                        <br>
                        V = 1101
                        <br>
                        E = 1110
                        <br>
                        _ = 1111
                        <br>
                        <br>
                        The final string:
                        <br>
                        110000010100010100100100001111101001101101
                        <br>
                        <br>
                        Try parsing it, and convince yourself that there is
                        only one possible interpretation of it. That is what
                        the prefix coding buys us.
                    </p>
                </details>


                <details>
                    <summary class="sum2">
                    Correctness of Huffman's algorithm
                    </summary>

                    <p>
                        We begin operating on an alphabet &Sigma;. At each step,
                        we create a new alphabet, &Sigma;', with two symbols of
                        &Sigma; replaced by a new "meta-symbol".
                        <br>
                        <br>
                        <b>Base case</b>: For an alphabet of two symbols, the
                        algorithm outputs 0 for one of them, and 1 for the
                        other. And that is clearly optimal! (An alphabet of
                        size 1 is a non-problem!)
                        <br>
                        <br>
                        <b>Inductive step</b>: Assume the algorithm is correct
                        for input of size <i>n</i> - 1.
                        <br>
                        At each step in the algorithm, we replace the two least
                        frequent remaining symbols <i>a</i> and <i>b</i> with a
                        new symbol <i>ab</i>, whose probability is the sum of
                        the probabilities of <i>a</i> and <i>b</i>.
                        <br>
                        We always want the lowest frequency symbols to have the
                        longest encoding length.
                        <br>
                        Any choice among symbols at the lowest frequency will
                        be fine, since they all have equally low frequency. So
                        we can pair any of those lowest frequency symbols as we
                        wish.
                        <br>
                        Now assume that there is an encoding &Sigma;'' that is
                        derived from &Sigma; (like &Sigma;') but differs in
                        choosing to combine <i>x</i> and <i>y</i> into a
                        <i>xy</i>. But since we made the greedy choice,
                        <i>xy</i> can be at best tied with <i>ab</i> meaning
                        &Sigma;'' is at best another optimal encoding, and our
                        encoding &Sigma;' is optimal after all.

                    </p>
                </details>
            </details>


            <details>
                <summary class="sum1">
                    Matroids and greedy methods
                </summary>

                <p>
                <img
                src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/b7/Vamos_matroid.svg/220px-Vamos_matroid.svg.png">
                </p>

                <details>
                    <summary class="sum2">
                    Matroids
                    </summary>

                    <h4>
                        A graph
                    </h4>
                    <p>
                        Consider the following graph, where the edges represent
                        roads and the vertices towns:
                        <br>
                        <br>
                        <img src="graphics/MatroidGraph.png">
                        <br>
                        <br>
                        If we want to build a set of roads that are only built
                        if there is no other route between towns, what sets are
                        possible?
                        <br>
                    </p>
                    <ul>
                        <li>&empty;
                        </li>
                        <li>{a} {b} {c} {d} {e}
                        </li>
                        <li>{a, b} {a, c} {a, d} {a, e} {b, c} {b, d} {b, e}
                            {c, d} {c, e}
                        </li>
                        <li>{a, b, c} {a, b, d}, {a, b, e} {a, c, d} {a, c, e}
                        </li>
                    </ul>
                    <p>
                        Notice:
                    </p>
                    <ul>
                        <li>f is useless!
                        </li>
                        <li>a is in every maximal set.
                        </li>
                        <li>d and e are never in the same set.
                        </li>
                        <li>b, c and d are never in the same set.
                        </li>
                        <li>b, c and e are never in the same set.
                        </li>
                    </ul>

                    <h4>
                        A vector space
                    </h4>
                    <p>
                        Now look at the following vector space in
                        &#8477;<sup>3</sup>:
                        <br>
                        <br>
                        <img src="graphics/MatroidVectors.png">
                        <br>
                        (f is the vector 0, 0, 0.)
                        <br>
                        <br>
                        What sets of linearly independent vectors are possible?
                    </p>
                    <ul>
                        <li>&empty;
                        </li>
                        <li>{a} {b} {c} {d} {e}
                        </li>
                        <li>{a, b} {a, c} {a, d} {a, e} {b, c} {b, d} {b, e}
                            {c, d} {c, e}
                        </li>
                        <li>{a, b, c} {a, b, d}, {a, b, e} {a, c, d} {a, c, e}
                        </li>
                    </ul>
                    <p>
                        Notice:
                    </p>
                    <ul>
                        <li>f is useless!
                        </li>
                        <li>a is in every maximal set.
                        </li>
                        <li>d and e are never in the same set.
                        </li>
                        <li>b, c and d are never in the same set.
                        </li>
                        <li>b, c and e are never in the same set.
                        </li>
                    </ul>


                    <h4>
                        A matching problem
                    </h4>

                    <p>
                        You live in a small town with 3 women and 5 men who are
                        single but might be married off. There is a town
                        matchmaker who makes money by arranging marriages, and
                        so he wants to arrange as many as possible.
                        <br>
                        In this town, it's "ladies' choice," and the women are
                        numbered 1-3, and the men are a-f.
                        <br>
                        <br>
                        <img src="graphics/MatroidMatching.png">
                        <br>
                        <br>
                        What sets of matches are possible?
                    </p>
                    <ul>
                        <li>&empty;
                        </li>
                        <li>{a} {b} {c} {d} {e}
                        </li>
                        <li>{a, b} {a, c} {a, d} {a, e} {b, c} {b, d} {b, e}
                            {c, d} {c, e}
                        </li>
                        <li>{a, b, c} {a, b, d}, {a, b, e} {a, c, d} {a, c, e}
                        </li>
                    </ul>
                    <p>
                        Notice:
                    </p>
                    <ul>
                        <li>f is useless!
                        </li>
                        <li>a is in every maximal set.
                        </li>
                        <li>d and e are never in the same set.
                        </li>
                        <li>b, c and d are never in the same set.
                        </li>
                        <li>b, c and e are never in the same set.
                        </li>
                    </ul>

                    <h4>
                        The definition of a matroid
                    </h4>
                    <p>
                        We are looking at general
                        conditions for <i>independence</i>
                        of choices. All three situations turn out to be
                        surprisingly similar. They can all
                        be modeled using <i>matroids</i>.
                        <br>
                        <br>
                        We have a matroid when the following independence
                        conditions are satisfied:
                    </p>
                    <ol>
                        <li>&empty; is independent.
                        </li>
                        <li>If set J is independent and I is a subset of J,
                            then I is independent.
                        </li>
                        <li>If I and J are independent, and cardinality(I) &lt;
                            cardinality(J), then there is some <i>j</i> in J
                                and not in I, so that I &cup; <i>j</i> is also
                                independent.
                        </li>
                    </ol>

                    <p>
                        A matroid consists of (S, I), where S is a set, and I
                        is a set of subsets of S, for which axioms 1-3
                        above are satisfied.
                        <br>
                        <br>
                        All three situations described above, the vector space,
                        the graph, and the matching problem, turn out to be the
                        <i>same</i> matroid.
                        (Technically, they are <i>isomorphic</i> matroids.)
                    </p>

                    <h4>
                        The bases of a matroid
                    </h4>

                    <p>
                        A subset in I is a <i>basis</i> for a
                        matroid if it is a <i>maximal</i>
                        subset, which here means it is not contained in any
                        larger subset that is in I.
                        <br>
                        <br>
                        So in the above examples, the bases are:
                        <br>
                        {a, b, c} {a, b, d}, {a, b, e} {a, c, d} {a, c, e}
                        <br>
                        <br>
                        <b>Theorem</b>:
                        Every basis of a matroid is of the same size.
                        <br>
                        <b>Proof</b>: Let assume that there are some bases
                        A and B of a matroid such that |B| &lt; |A|.
                        <br>
                        Then by the exchange axiom (#3 above),
                        there is some
                        element <i>a</i> of A that can be moved
                        into B, and B
                        will still be independent.
                        <br>
                        Therefore, it was <i>not</i>
                        a maximal independent subset after
                        all!
                        <br>
                        <br>
                        Translation into the different matroid realms:
                        <br>
                        <br>
                        The dimension of a vector space is the
                        size of any of its bases.
                        <br>
                        <br>
                        Every spanning tree has the same number of edges.
                        <br>
                        <br>
                        We are proving things about vector spaces and graphs
                        simply by examining the axioms of matroids!
                    </p>


                    <h4>
                        Credit
                    </h4>

                    <p>
                        This section draws on lectures by Federico Ardila:
                        <a href="https://www.youtube.com/watch?v=4EvpzV_3RXI">
                            here
                        </a>
                        and
                        <a
                           href="https://www.youtube.com/watch?v=pe5MaEugAwg&list=PL-XzhVrXIVeSu_b29hbX5xJ0bRThokU8a">
                            here</a>.
                    </p>
                </details>

                <details>
                    <summary class="sum2">
                    Greedy algorithms on a weighted matroid
                    </summary>
                    <p>
                        <b>Q</b>: Why do greedy algorithms work on a matroid?
                        <br>
                        <b>A</b>: Independence!
                    </p>
                    <p>
                        We often have a problem that can be considered as
                        an instance of finding a maximum (or minimum)
                        weight independent subset in a weighted matroid.
                        Let us look at <a
                            href="MinimumSpanningTrees.html#Kruskal">
                            Kruskal's algorithm</a>.
                    </p>
                </details>
            </details>


            <details>
                <summary class="sum1">
                    A task-scheduling problem as a matroid
                </summary>

                <p>
                    <img
                    src="https://upload.wikimedia.org/wikipedia/commons/thumb/0/0c/Thread_pool.svg/400px-Thread_pool.svg.png">
                    <br>
                    <br>
                    The surprise here is that we can
                    simply greedily grab tasks in
                    order of increasing deadlines, and our algorithm will work.
                </p>
            </details>

            <h2>
                Source Code
            </h2>
            <p>
<!--include GreedyAlgorithms_langs.txt -->
            </p>
            <details>
                <summary class="sum1">
                    For Further Study
                </summary>
                <ul>
                    <li><a href="https://en.wikipedia.org/wiki/Greedy_algorithm">
                            Greedy algorithm
                        </a>
                    </li>
                    <li><a href="https://en.wikipedia.org/wiki/Huffman_coding">
                            Huffman coding
                        </a>
                    </li>
                    <li><a href="https://en.wikipedia.org/wiki/Matroid">
                            Matroid
                        </a>
                    </li>
                </ul>
            </details>

            <details>
                <summary class="sum1">
                    Homework
                </summary>
                <ol>
                    <li id="hw1">
                        Our intuition might tell us that choosing the shortest
                        subway path from MetroTech Center to Yankee Stadium
                        is a simpler problem than choosing a minimum
                        spanning tree for all New York subway
                        stations. Yet the latter can be solved with a greedy algorithm,
                        while the first cannot. Why?
                        <br>
                        <br>
                        <b>Answer</b>: The spanning tree problem is a matroid,
                        and so deals with indpendent sub-problems. The
                        different paths between subway stops are <i>not</i>
                        independent: some choices foreclose other choices.
                        <br>
                    </li>
                    <li>Why is the run-time analysis of the rod cutting problem not
                        the same as that of the matrix chain problem?
                        <br>
                        <br>
                        <b>Answer</b>:The matrix chain order problem can nest
                        the sub-problems in many ways, while the rod-cutting
                        problem simply makes one level of cuts. It would be
                        more like the matrix problem if it also bundled
                        packages of cut rods into higher level bundles.
                        <br>
                        Or, rod cutting: ---|--|--|--|------|--
                        <br>
                        The vertical lines represent cuts.
                        <br>
                        Whereas, matrix chaining: (((A A) (A (A A))) (A A) ((A A
                        A)) A)
                        <br>
                    </li>
                    <li>For the activity selection problem, besides simply
                        choosing the activity this finishes first, what other
                        greedy choices could we make?
                        <br>
                        <br>
                        <b>Answer</b>: The activity that starts first, the
                        activity with the smallest time requirement.
                        <br>
                    </li>
                    <li>On page 419, line 2 of pseudo-code loops, and the
                        comment describing why it is looping is incorrect. What
                        is actually going on there? Why isn't the code just
                        grabbing the first element in the activity array, which
                        must be the one that finishes first?
                        <br>
                        <br>
                        <b>Answer</b>: The code has to find not the first
                        activity that finishes, but the first one that starts
                        after the "current" time and finishes first. So it must
                        loop until it finds that item.
                        <br>
                    </li>
                    <li>Show that the fractional knapsack problem (p. 425) has the
                        greedy choice property.
                        <br>
                        <br>
                        <b>Answer</b>: We can take as much as possible of the
                        highest value per weight item first. If we fill the
                        knapsack, we are done. If not, we can take as much as
                        possible of the second-highest value item, and repeat
                        until the knapsack is full. Each choice is completely
                        independent of subsequent choices.
                    </li>
                </ol>
            </details>
    </body>
<!--include google_analytics.txt -->
</html>
